{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from glob import glob\n",
    "# import pandas as pd\n",
    "\n",
    "# ## 데이터 너무 크기 때문에 평가 셋으로 모델 학습\n",
    "\n",
    "# # 외국인 및 한국어 말하기 평가 셋이 있는 경로 지정\n",
    "# path_ko = \"C:/Users/jjw28/Downloads/자유대화 음성(일반남녀)/Validation\"\n",
    "# path_foreign =  \"C:\\\\Users\\\\jjw28\\\\Downloads\\\\131.인공지능 학습을 위한 외국인 한국어 발화 음성 데이터\\\\01.데이터_new_20220719\\\\2.Validation\\\\라벨링데이터\"\n",
    "\n",
    "# # 각 경로에 있는 라벨 데이터 확인\n",
    "# foreign_json_list = glob(path_foreign + '/**/**/*.json')\n",
    "# kor_json_list = glob(path_ko + '/라벨1.AI챗봇/**/*.json')\n",
    "\n",
    "# print(len(foreign_json_list), len(kor_json_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from G2P.KoG2Padvanced import KoG2Padvanced\n",
    "# import re\n",
    "# from tqdm import tqdm\n",
    "# from glob import glob\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# # 외국인 및 말하기 평가 셋이 있는 경로 지정\n",
    "# path_foreign =  \"C:\\\\Users\\\\jjw28\\\\Downloads\\\\131.인공지능 학습을 위한 외국인 한국어 발화 음성 데이터\\\\01.데이터_new_20220719\\\\2.Validation\\\\라벨링데이터\"\n",
    "\n",
    "# # 각 경로에 있는 라벨 데이터 확인\n",
    "# foreign_json_list = glob(path_foreign + '/**/**/*.json')\n",
    "\n",
    "# # 두번째 'ㅇ'이 들어가는 글자에 경우 모음만 나와서 이를 수정하는 함수\n",
    "# def vowel_change(hangul_string):\n",
    "#     vowels = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ',\n",
    "#                        'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ']\n",
    "#     vowels_change = ['아', '애', '야', '얘', '어', '에', '여', '예', '오', '와',\n",
    "#                      '왜', '외', '요', '우', '워', '웨', '위', '유', '으', '의', '이']\n",
    "#     dic = {i:k for i, k in zip(vowels,vowels_change)}\n",
    "    \n",
    "#     pattern = \"[\" + \"\".join(vowels) + \"]\"\n",
    "#     result = re.sub(pattern, lambda x: dic[x.group(0)], hangul_string)\n",
    "#     return result\n",
    "\n",
    "# # 텍스트 g2p 변환을 위한 함수\n",
    "# def foreign_g2p(text):\n",
    "#     text = re.sub('[^가-힣\\s]', '', text)\n",
    "#     text = re.sub('\\s+', ' ', text)\n",
    "#     text = KoG2Padvanced(text)\n",
    "#     text = vowel_change(text)\n",
    "#     return text\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     # 영어가 있는 텍스트를 제외하기 위한 패턴 지정\n",
    "#     pattern = re.compile(r'[A-Za-z]')\n",
    "\n",
    "#     # 한 번에 데이터프레임에 넣기 위해 임시 리스트 생성\n",
    "#     tmp_list = []\n",
    "    \n",
    "#     # 외국인 json파일 경로가 있는 리스트 순회\n",
    "#     for foreign_json in tqdm(foreign_json_list, desc='to_csv..'):\n",
    "\n",
    "#         # 각 음성에 대한 JSON 파일 불러오기\n",
    "#         with open(foreign_json, 'r') as jsf:\n",
    "#             data = json.load(jsf)\n",
    "\n",
    "#         # 필요한 값들 JSON에서 추출\n",
    "#         audio_path = foreign_json.replace('라벨링데이터', '원천데이터').replace('json', 'wav')\n",
    "#         if data['transcription'].get('AnswerLabelText', False):\n",
    "#             text = data['transcription'].get('AnswerLabelText', False)\n",
    "#         else:\n",
    "#             text = data['transcription']['ReadingLabelText']\n",
    "\n",
    "#         # 영어가 포함되면 데이터 셋에 포함되지 않게 다음으로 넘어감\n",
    "#         if bool(pattern.search(text)):\n",
    "#             continue\n",
    "\n",
    "#         g2p_text = foreign_g2p(text)\n",
    "#         country = data['residence_info']['country']\n",
    "#         learning_period = data['skill_info']['LearningPeriod']\n",
    "#         record_time = data['file_info']['recordTime']\n",
    "\n",
    "#         tmp_list.append([audio_path, text, g2p_text, country, learning_period, record_time])\n",
    "\n",
    "#     # 외국인 음성 데이터에 대한 전체 경로 및 메타데이터 저장을 위한 데이터프레임\n",
    "#     foreign_meta_csv = pd.DataFrame(tmp_list, columns = ['audio_path', 'text', 'g2p_text','county', 'learning_period', 'record_time'])\n",
    "#     foreign_meta_csv.to_csv('./data/foregin_meta_csv.csv', index = False, encoding = 'utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from G2P.KoG2Padvanced import KoG2Padvanced\n",
    "# import re\n",
    "# from tqdm import tqdm\n",
    "# from glob import glob\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# # 두번째 'ㅇ'이 들어가는 글자에 경우 모음만 나와서 이를 수정하는 함수\n",
    "# def vowel_change(hangul_string):\n",
    "#     vowels = ['ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ',\n",
    "#                        'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ']\n",
    "#     vowels_change = ['아', '애', '야', '얘', '어', '에', '여', '예', '오', '와',\n",
    "#                      '왜', '외', '요', '우', '워', '웨', '위', '유', '으', '의', '이']\n",
    "#     dic = {i:k for i, k in zip(vowels,vowels_change)}\n",
    "    \n",
    "#     pattern = \"[\" + \"\".join(vowels) + \"]\"\n",
    "#     result = re.sub(pattern, lambda x: dic[x.group(0)], hangul_string)\n",
    "#     return result\n",
    "\n",
    "# # 텍스트 g2p 변환을 위한 함수\n",
    "# def foreign_g2p(text):\n",
    "#     text = re.sub('[^가-힣\\s]', '', text)\n",
    "#     text = re.sub('\\s+', ' ', text)\n",
    "#     text = KoG2Padvanced(text)\n",
    "#     text = vowel_change(text)\n",
    "#     return text\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     # 한국인 말하기 평가 셋이 있는 경로 지정\n",
    "#     path_ko = \"C:/Users/jjw28/Downloads/자유대화 음성(일반남녀)/Validation\"\n",
    "    \n",
    "#     # 각 경로에 있는 라벨 데이터 확인\n",
    "#     kor_json_list = glob(path_ko + '/라벨1.AI챗봇/**/*.json')\n",
    "\n",
    "#     # 영어가 있는 텍스트를 제외하기 위한 패턴 지정\n",
    "#     pattern = re.compile(r'[A-Za-z]')\n",
    "\n",
    "#     # 한 번에 데이터프레임에 넣기 위해 임시 리스트 생성\n",
    "#     tmp_list = []\n",
    "    \n",
    "#     # 외국인 json파일 경로가 있는 리스트 순회\n",
    "#     for kor_json in tqdm(kor_json_list, desc='to_csv..'):\n",
    "\n",
    "#         # 각 음성에 대한 JSON 파일 불러오기\n",
    "#         with open(kor_json, 'r', encoding='utf-8') as jsf:\n",
    "#             data = json.load(jsf)\n",
    "\n",
    "#         # 필요한 값들 JSON에서 추출\n",
    "#         audio_path = kor_json.replace('라벨1.AI챗봇', '원천1.AI챗봇').replace('json', 'wav')\n",
    "#         text = data['발화정보']['stt']\n",
    "\n",
    "#         # 영어가 포함되면 데이터 셋에 포함되지 않게 다음으로 넘어감\n",
    "#         if bool(pattern.search(text)):\n",
    "#             continue\n",
    "\n",
    "#         g2p_text = foreign_g2p(text)\n",
    "#         country = 'kor'\n",
    "#         learning_period = np.nan\n",
    "#         record_time = data['발화정보']['recrdTime']\n",
    "\n",
    "#         tmp_list.append([audio_path, text, g2p_text, country, learning_period, record_time])\n",
    "\n",
    "#     # 외국인 음성 데이터에 대한 전체 경로 및 메타데이터 저장을 위한 데이터프레임\n",
    "#     kor_meta_csv = pd.DataFrame(tmp_list, columns = ['audio_path', 'text', 'g2p_text','county', 'learning_period', 'record_time'])\n",
    "#     kor_meta_csv.to_csv('./data/kor_meta_csv.csv', index = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # 메타데이터 전처리한 csv 불러오기\n",
    "#     foreign_csv = pd.read_csv('C:/Users/jjw28/OneDrive/바탕 화면/wav2vec2/data/foregin_meta_csv.csv', encoding='utf-8')\n",
    "#     kor_csv = pd.read_csv('C:/Users/jjw28/OneDrive/바탕 화면/wav2vec2/data/kor_meta_csv.csv', encoding='utf-8')\n",
    "\n",
    "#     # 국가 잘못 처리 한 것 수정 및 학습기간이 24개월 이상만 사용\n",
    "#     foreign_csv['county'] = foreign_csv['audio_path'].map(lambda x : x.split('\\\\')[-1][:2])\n",
    "#     foreign_csv = foreign_csv[foreign_csv['learning_period'] >= 24]\n",
    "\n",
    "#     # 학습 데이터 셋 비율을 3:1로 맞추기 위해 한국인 데이터셋에서 5만개 랜덤 추출\n",
    "#     random_kor = kor_csv.sample(n=50000, random_state=23)\n",
    "#     random_kor['county'] = 'KR'\n",
    "\n",
    "#     # 사용할 데이터 셋에 대한 최종 메타데이터 정리 csv저장\n",
    "#     final_dataset_df = pd.concat([foreign_csv, random_kor], ignore_index=True)\n",
    "#     final_dataset_df = final_dataset_df.rename(columns={'county':'country'})\n",
    "\n",
    "#     os.chdir('C:/Users/jjw28/OneDrive/바탕 화면/wav2vec2/data')\n",
    "#     final_dataset_df.to_csv('./final_dataset_df.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 151485/151485 [00:00<00:00, 427819.31 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# from datasets import Dataset, Audio\n",
    "# import pandas as pd\n",
    "# import json\n",
    "# import os\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#   datasets_df = pd.read_csv('C:/Users/jjw28/OneDrive/바탕 화면/wav2vec2/data/final_dataset_df.csv', encoding='utf-8')\n",
    "#   audio_list = list(datasets_df['audio_path'])\n",
    "#   g2p_txt = list(datasets_df['g2p_text'])\n",
    "#   country = list(datasets_df['country'])\n",
    "\n",
    "#   ds = Dataset.from_dict({'audio' : audio_list,\n",
    "#                         \"transcripts\": g2p_txt,\n",
    "#                         \"country\" : country}).cast_column('audio', Audio(sampling_rate=16000))\n",
    "\n",
    "#   def extract_all_chars(batch):\n",
    "#     all_text = \" \".join(batch[\"transcripts\"])\n",
    "#     vocab = list(set(all_text))\n",
    "#     return {\"vocab\": [vocab], \"all_text\": [all_text]}\n",
    "\n",
    "#   vocabs = ds.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=ds.column_names)\n",
    "#   vocab_list = list(set(vocabs[\"vocab\"][0]))\n",
    "\n",
    "#   vocab_dict = {v: k for k, v in enumerate(vocab_list)}\n",
    "#   vocab_dict\n",
    "\n",
    "#   vocab_dict[\"|\"] = vocab_dict[\" \"]\n",
    "#   del vocab_dict[\" \"]\n",
    "#   vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
    "#   vocab_dict[\"[PAD]\"] = len(vocab_dict)\n",
    "\n",
    "#   os.chdir('C:\\\\Users\\\\jjw28\\\\OneDrive\\\\바탕 화면\\\\wav2vec2\\\\data')\n",
    "#   with open('vocab.json', 'w') as vocab_file:\n",
    "#       json.dump(vocab_dict, vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:/Users/jjw28/OneDrive/바탕 화면/wav2vec2/model/custom_tokenizer\\\\tokenizer_config.json',\n",
       " 'C:/Users/jjw28/OneDrive/바탕 화면/wav2vec2/model/custom_tokenizer\\\\special_tokens_map.json',\n",
       " 'C:/Users/jjw28/OneDrive/바탕 화면/wav2vec2/model/custom_tokenizer\\\\vocab.json',\n",
       " 'C:/Users/jjw28/OneDrive/바탕 화면/wav2vec2/model/custom_tokenizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor, Wav2Vec2Processor\n",
    "import IPython.display as ipd\n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer(\"C:/Users/jjw28/OneDrive/바탕 화면/wav2vec2/data/vocab.json\", \n",
    "                                 unk_token=\"[UNK]\", \n",
    "                                 pad_token=\"[PAD]\", \n",
    "                                 word_delimiter_token=\"|\")\n",
    "tokenizer.save_pretrained('C:/Users/jjw28/OneDrive/바탕 화면/wav2vec2/model/custom_tokenizer')\n",
    "\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, \n",
    "                                             padding_value=0.0, \n",
    "                                             do_normalize=True, \n",
    "                                                return_attention_mask=False)\n",
    "\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)\n",
    "processor.save_pretrained('C:/Users/jjw28/OneDrive/바탕 화면/wav2vec2/model/custom_processor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import Dataset, Audio\n",
    "# import IPython.display as ipd\n",
    "# import pandas as pd\n",
    "# from transformers import Wav2Vec2Processor\n",
    "\n",
    "# if __name__ ==\"__main__\":\n",
    "#     processor = Wav2Vec2Processor.from_pretrained('C:/Users/jjw28/OneDrive/바탕 화면/wav2vec2/model/custom_processor')\n",
    "\n",
    "#     datasets_df = pd.read_csv('C:/Users/jjw28/OneDrive/바탕 화면/wav2vec2/data/final_dataset_df.csv', encoding='utf-8')\n",
    "#     audio_list = list(datasets_df['audio_path'])\n",
    "#     g2p_txt = list(datasets_df['g2p_text'])\n",
    "#     country = list(datasets_df['country'])\n",
    "\n",
    "#     ds = Dataset.from_dict({'audio' : audio_list,\n",
    "#                         \"transcripts\": g2p_txt,\n",
    "#                         \"country\" : country}).cast_column('audio', Audio(sampling_rate=16000))\n",
    "#     ds = ds.class_encode_column(\"country\")\n",
    "#     ds = ds.train_test_split(test_size=0.1, shuffle=True, stratify_by_column='country')\n",
    "\n",
    "#     def prepare_dataset(batch):\n",
    "#         audio = batch[\"audio\"]\n",
    "\n",
    "#         batch[\"input_values\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "#         batch[\"input_length\"] = len(batch[\"input_values\"])\n",
    "        \n",
    "#         with processor.as_target_processor():\n",
    "#             batch[\"labels\"] = processor(batch[\"transcripts\"]).input_ids\n",
    "#         return batch\n",
    "\n",
    "#     ds = ds.map(prepare_dataset, remove_columns=ds.column_names[\"train\"])\n",
    "#     ds.save_to_disk('C:/Users/jjw28/OneDrive/바탕 화면/wav2vec2/data/pre_datasets')\n",
    "\n",
    "#     print('-------------finish-------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', 'transcripts', 'country'],\n",
       "        num_rows: 121188\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['audio', 'transcripts', 'country'],\n",
       "        num_rows: 30297\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "import torch\n",
    "from jiwer import wer\n",
    "from utils.DataCollatorCTCWithPadding import DataCollatorCTCWithPadding\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"./model/custom_processor\")\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"kresnik/wav2vec2-large-xlsr-korean\")    \n",
    "\n",
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, Audio\n",
    "import IPython.display as ipd\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoFeatureExtractor, Wav2Vec2ProcessorWithLM\n",
    "from pyctcdecode import build_ctcdecoder\n",
    "from jamo import h2j, j2hcj\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    feature_extractor = AutoFeatureExtractor.from_pretrained(\"42MARU/ko-spelling-wav2vec2-conformer-del-1s\")\n",
    "    feature_extractor.save_pretrained('C:/Users/jjw28/OneDrive/바탕 화면/wav2vec2/model/feature_extractor_conformer')\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"42MARU/ko-spelling-wav2vec2-conformer-del-1s\")\n",
    "    tokenizer.save_pretrained('C:/Users/jjw28/OneDrive/바탕 화면/wav2vec2/model/feature_extractor_tokenizer')\n",
    "\n",
    "    beamsearch_decoder = build_ctcdecoder(\n",
    "        labels=list(tokenizer.encoder.keys()),\n",
    "        kenlm_model_path=None,\n",
    "    )\n",
    "    from jamo import h2j, j2hcj\n",
    "\n",
    "    text = \"안녕 하세요\"\n",
    "\n",
    "    jamo_str = j2hcj(h2j(text))\n",
    "    print(jamo_str)\n",
    "    processor = Wav2Vec2ProcessorWithLM(\n",
    "        feature_extractor=feature_extractor, tokenizer=tokenizer, decoder=beamsearch_decoder\n",
    "    )\n",
    "    datasets_df = pd.read_csv('C:/Users/jjw28/OneDrive/바탕 화면/wav2vec2/data/final_dataset_df.csv', encoding='utf-8')   \n",
    "    _, datasets_df = train_test_split(datasets_df, stratify=datasets_df['country'], test_size = 0.25, random_state=23)\n",
    "    datasets_df['text'] = datasets_df['text'].map(lambda x : j2hcj(h2j(x))).str.replace(' ', '|')\n",
    "    \n",
    "    audio_list = list(datasets_df['audio_path'])\n",
    "    txt = list(datasets_df['text'])\n",
    "    country = list(datasets_df['country'])\n",
    "\n",
    "    ds = Dataset.from_dict({'audio' : audio_list,\n",
    "                        \"transcripts\": txt,\n",
    "                        \"country\" : country}).cast_column('audio', Audio(sampling_rate=16000))\n",
    "    ds = ds.class_encode_column(\"country\")\n",
    "    ds = ds.train_test_split(test_size=0.1, shuffle=True, stratify_by_column='country')\n",
    "\n",
    "    def prepare_dataset(batch):\n",
    "        audio = batch[\"audio\"]\n",
    "\n",
    "        batch[\"input_values\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "        # batch[\"input_length\"] = len(batch[\"input_values\"])\n",
    "        \n",
    "        with processor.as_target_processor():\n",
    "            batch[\"labels\"] = processor(batch[\"transcripts\"]).input_ids\n",
    "        return batch\n",
    "\n",
    "    ds = ds.map(prepare_dataset, remove_columns=ds.column_names[\"train\"])\n",
    "    ds.save_to_disk('C:/Users/jjw28/OneDrive/바탕 화면/wav2vec2/data/pre_datasets')\n",
    "\n",
    "    print('-------------finish-------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "KR    12500\n",
       "CN     5368\n",
       "EX     4903\n",
       "EN     4369\n",
       "VN     4131\n",
       "JP     3518\n",
       "TH     3083\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "_, df = train_test_split(datasets_df, stratify=datasets_df['country'], test_size = 0.25, random_state=23)\n",
    "# df['country'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "for_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
